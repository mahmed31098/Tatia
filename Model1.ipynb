{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9f21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56c13f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import pipeline\n",
    "from transformers import Trainer\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a494f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4ccacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa8248e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43845a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b60180",
   "metadata": {},
   "source": [
    "Those are the labels as integers ready for training, but they’re not necessarily useful when we want to inspect the data. Like for text classification, we can access the correspondence between those integers and the label names by looking at the features attribute of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f70f4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = dataset[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa43dde",
   "metadata": {},
   "source": [
    "So this column contains elements that are sequences of ClassLabels. The type of the elements of the sequence is in the feature attribute of this ner_feature, and we can access the list of names by looking at the names attribute of that feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d183b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76160aed",
   "metadata": {},
   "source": [
    "O means the word doesn’t correspond to any entity.\n",
    "\n",
    "B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n",
    "\n",
    "B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n",
    "\n",
    "B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n",
    "\n",
    "B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity like nationality, event, product, work of art etc\n",
    "\n",
    "Now decoding the labels saw earlier gives this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50e4ad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU    rejects German call to boycott British lamb . \n",
      "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
     ]
    }
   ],
   "source": [
    "words = dataset[\"train\"][0][\"tokens\"]\n",
    "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89276b76",
   "metadata": {},
   "source": [
    "_Texts need to be converted to token IDs before the model can make sense of them._\n",
    "\n",
    "_I just need to warn the tokenizer with a special flag._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f7c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a47973de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb0dd3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To tokenize a pre-tokenized input, we can use our tokenizer as usual and just add is_split_into_words=True:\n",
    "\n",
    "inputs = tokenizer(dataset[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens() #The word lamb, however, was tokenized into two subwords, la and ##mb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46390074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a4de3",
   "metadata": {},
   "source": [
    "*With a tiny bit of work, I can then expand our label list to match the tokens. The first rule I’ll apply is that special tokens get a label of -100. This is because by default -100 is an index that is ignored in the loss function we will use (cross entropy). Then, each token gets the same label as the token that started the word it’s inside, since they are part of the same entity. For tokens inside a word but not at the beginning, I replace the B- with I- (since the token does not begin the entity):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1bed671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e7f0906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "#print(dataset[\"train\"][0][\"tokens\"])\n",
    "labels\n",
    "#print(inputs.tokens())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bc29494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_labels_with_tokens(labels, word_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e56e1",
   "metadata": {},
   "source": [
    "*As I can see, my function added the -100 for the two special tokens at the beginning and the end, and a new 0 for our word that was split into two tokens.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26f0e3",
   "metadata": {},
   "source": [
    "Below is the function that processes a list of examples and use the Dataset.map() method with the option batched=True. The only thing that is different from my previous example is that the word_ids() function needs to get the index of the example I want the word IDs of when the inputs to the tokenizer are lists of texts (or in my case, list of lists of words), so I add that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a349fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfff9efa",
   "metadata": {},
   "source": [
    "I can now apply all that preprocessing in one go on the other splits of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c3d4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0b040",
   "metadata": {},
   "source": [
    "## Fine-tuning the model with the Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a46757",
   "metadata": {},
   "source": [
    "### Data collation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1be0a",
   "metadata": {},
   "source": [
    "Here my labels should be padded the exact same way as the inputs so that they stay the same size, using -100 as a value so that the corresponding predictions are ignored in the loss computation.\n",
    "\n",
    "This is all done by a DataCollatorForTokenClassification. Like the DataCollatorWithPadding, it takes the tokenizer used to preprocess the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92a9620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cba7ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ahmed\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac116478",
   "metadata": {},
   "source": [
    "To test this on a few samples, I can just call it on a list of examples from our tokenized training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dac9598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e94b8",
   "metadata": {},
   "source": [
    "Let’s compare this to the labels for the first and second elements in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8bc1a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
      "[-100, 1, 2, -100]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99be8c5",
   "metadata": {},
   "source": [
    "As I can see, the second set of labels has been padded to the length of the first one using -100s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d468e7d",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ff5b3",
   "metadata": {},
   "source": [
    "To have the Trainer compute a metric every epoch, I will need to define a compute_metrics() function that takes the arrays of predictions and labels, and returns a dictionary with the metric names and values.\n",
    "\n",
    "I first need to install the seqeval library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed8b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a747c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1ca5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c0c9a8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade transformers evaluate tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb6b542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-probability in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Collecting tensorflow-probability\n",
      "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 995.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: transformers in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: evaluate in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-probability) (0.1.8)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-probability) (2.0.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorflow-probability) (5.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: dill in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from evaluate) (2023.10.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from evaluate) (1.4.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from evaluate) (2.16.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: tensorflow-probability\n",
      "  Attempting uninstall: tensorflow-probability\n",
      "    Found existing installation: tensorflow-probability 0.20.1\n",
      "    Uninstalling tensorflow-probability-0.20.1:\n",
      "      Successfully uninstalled tensorflow-probability-0.20.1\n",
      "Successfully installed tensorflow-probability-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\ahmed\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "## pip install --upgrade tensorflow tensorflow-probability transformers evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f01f350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ahmed\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ahmed\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e153ce02",
   "metadata": {},
   "source": [
    "This metric does not behave like the standard accuracy: it will actually take the lists of labels as strings, not integers, so I will need to fully decode the predictions and labels before passing them to the metric. Let’s see how it works. First, I’ll get the labels for my first training example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b65e954b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39a6a2",
   "metadata": {},
   "source": [
    "We can then create fake predictions for those by just changing the value at index 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68c7e2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 1.0,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 2},\n",
       " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 0.6666666666666666,\n",
       " 'overall_f1': 0.8,\n",
       " 'overall_accuracy': 0.8888888888888888}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "metric.compute(predictions=[predictions], references=[labels])\n",
    "#Note that the metric takes a list of predictions (not just one) and a list of labels. Here’s the output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfbcd2",
   "metadata": {},
   "source": [
    "This is sending back a lot of information! I get the precision, recall, and F1 score for each separate entity, as well as overall. For our metric computation I will only keep the overall score.\n",
    "\n",
    "This compute_metrics() function first takes the argmax of the logits to convert them to predictions (as usual, the logits and the probabilities are in the same order, so I don’t need to apply the softmax). Then I have to convert both labels and predictions from integers to strings. I remove all the values where the label is -100, then pass the results to the metric.compute() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acaaa565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f286c",
   "metadata": {},
   "source": [
    "Now that this is done, I am almost ready to define my Trainer. I just need a model to fine-tune!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d52f99",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52697ce8",
   "metadata": {},
   "source": [
    "Since I am working on a token classification problem, I will use the AutoModelForTokenClassification class. The main thing to remember when defining this model is to pass along some information on the number of labels I have. The easiest way to do this is to pass that number with the num_labels argument, but if I want a nice inference widget, it’s better to set the correct label correspondences instead.\n",
    "\n",
    "They should be set by two dictionaries, id2label and label2id, which contain the mappings from ID to label and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80ade4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61e5207e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-PER': 1,\n",
       " 'I-PER': 2,\n",
       " 'B-ORG': 3,\n",
       " 'I-ORG': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-LOC': 6,\n",
       " 'B-MISC': 7,\n",
       " 'I-MISC': 8}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f71ec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e8283",
   "metadata": {},
   "source": [
    "Now I can just pass them to the AutoModelForTokenClassification.from_pretrained() method, and they will be set in the model’s configuration and then properly saved and uploaded to the Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c349378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c1907",
   "metadata": {},
   "source": [
    "Let’s double-check that our model has the right number of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a6089d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aff8d7",
   "metadata": {},
   "source": [
    "### Fine-tuning the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e73258",
   "metadata": {},
   "source": [
    "I am now ready to train our model! I just need to do two last things before we define our Trainer: log in to Hugging Face and define our training arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "037abec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c116cd44764f74b7a1fd53ac0e912a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c184a06",
   "metadata": {},
   "source": [
    "I specify push_to_hub=True to indicate that we want to save the model and evaluate it at the end of every epoch, and that I want to upload our results to the Model Hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9564cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05789b",
   "metadata": {},
   "source": [
    "Finally, I just pass everything to the Trainer and launch the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0471bcd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5268/5268 4:21:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.080577</td>\n",
       "      <td>0.915631</td>\n",
       "      <td>0.929653</td>\n",
       "      <td>0.922589</td>\n",
       "      <td>0.979602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.060043</td>\n",
       "      <td>0.926708</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>0.935667</td>\n",
       "      <td>0.985342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.060809</td>\n",
       "      <td>0.930574</td>\n",
       "      <td>0.949680</td>\n",
       "      <td>0.940030</td>\n",
       "      <td>0.986166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5268, training_loss=0.06731020526263237, metrics={'train_runtime': 15682.6122, 'train_samples_per_second': 2.686, 'train_steps_per_second': 0.336, 'total_flos': 923635312577460.0, 'train_loss': 0.06731020526263237, 'epoch': 3.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8cbb41",
   "metadata": {},
   "source": [
    "Note that while the training happens, each time the model is saved (here, every epoch) it is uploaded to the Hub in the background. \n",
    "\n",
    "Once the training is complete, I use the push_to_hub() method to make sure we upload the most recent version of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87b31b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/muhammadahmad2622/bert-finetuned-ner/tree/main/'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bc47f",
   "metadata": {},
   "source": [
    "### Using the fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69f04c",
   "metadata": {},
   "source": [
    "To use the model locally in a pipeline, I have to specify the proper model identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09130eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9989286,\n",
       "  'word': 'Ahmed',\n",
       "  'start': 11,\n",
       "  'end': 16},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9950421,\n",
       "  'word': 'Unice',\n",
       "  'start': 31,\n",
       "  'end': 36},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9986689,\n",
       "  'word': 'Nice',\n",
       "  'start': 40,\n",
       "  'end': 44}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint='muhammadahmad2622/bert-finetuned-ner'\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "token_classifier(\"My name is Ahmed and I work at Unice in Nice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afd29f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9992379,\n",
       "  'word': 'Muhammad Ahmed',\n",
       "  'start': 11,\n",
       "  'end': 25},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9923763,\n",
       "  'word': 'Unice',\n",
       "  'start': 40,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.90186274,\n",
       "  'word': 'Nice Sophia',\n",
       "  'start': 49,\n",
       "  'end': 60}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier(\"My name is Muhammad Ahmed and I work at Unice in Nice Sophia.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
